{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CuDNN GRU in TensorFlow: Issues and Example Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gated recurrent units (GRUs) are a type of recurrent neural network designed to have a persistent memory that can capture long-term dependencies. This repository contains a frozen GRU-based waveform generator inspired by Google DeepMind's WaveRNN (2018).\n",
    "\n",
    "These are the four equations governing the CuDNN version of the GRU cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GRU equations](img/gru_small.png \"GRU equations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update gate $u$ (sometimes referred to as $z$) controls how much the hidden state is updated at each timestep by weighting the previous hidden state against a new candidate $\\tilde h$. The reset gate $r$ controls the creation of the candidate $\\tilde h$ by gating the contribution of the previous state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuDNN GRU in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CuDNN implementation of the GRU cell is very fast compared to a GRU implementation in native TensorFlow using `tf.while_loop` and explicit operations. For the WaveRNN model in this repository, CuDNN GRU yielded a __7.3x__ training speedup over the explicit version, reducing the length of training needed for convergence from 8-24 hours to 1-3 hours (depending on the size of the hidden state and other parameters). \n",
    "\n",
    "CuDNN GRU is supported by TF's `CudnnGRU` class, which has a weights buffer that is saved in a `CudnnOpaqueParamsSaveable` object and a `call(...)` method for running a forward step. The class also has methods for converting between TF and CuDNN canonical weights and biases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with TF's `CudnnGRU` --- and workaround"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the CuDNN RNN module is poorly documented, buggy, and difficult to work with. After slotting the CuDNN GRU into our WaveRNN model, I was unable to get the network to train at all, even after trying to manually avoid some of the problematic built-in functions. \n",
    "\n",
    "But there is a workaround: the `_forward(...)` method that directly handles the GRU forward-pass works just fine. So if we create a weight buffer of the correct shape and pass it to `_forward(...)`, we can run a Cudnn GRU without fussing with the rest of the module.\n",
    "\n",
    "First let's import TensorFlow, `cudnn_rnn_ops`, etc. (note: CuDNN requires __tensorflow-gpu__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define and initialize a weight buffer of the correct shape (`\"Kernel\"`) and pass it to CuDNN GRU's `_forward(...)` method. The function returns a node corresponding to the GRU outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cudnn_gru(inputs, input_channels, recurrent_size):\n",
    "    \"\"\"\n",
    "    Run the CuDNN GRU cell.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input tensor, shape [batch_size, timesteps, input_channels]\n",
    "        input_channels: Number of input channels\n",
    "        recurrent_size: Size of GRU hidden state\n",
    "        \n",
    "    Returns:\n",
    "        TF node corresponding to GRU outputs.\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    timesteps = tf.shape(inputs)[1]\n",
    "\n",
    "    initial_state = tf.zeros(\n",
    "        (1, batch_size, recurrent_size), dtype=tf.float32)\n",
    "    dummy = tf.constant([], dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"GRU\"):\n",
    "        kernel = tf.get_variable(\"Kernel\",\n",
    "            shape=[recurrent_size *\n",
    "                (3 * recurrent_size + 3 * input_channels + 6)],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    # Transpose inputs from batch-major to time-major for CuDNN GRU.\n",
    "    inputs = tf.transpose(inputs, [1, 0, 2])\n",
    "\n",
    "    # CuDNN GRU forward pass.\n",
    "    gru = tf.contrib.cudnn_rnn.CudnnGRU(1, recurrent_size)\n",
    "    hidden, _ = gru._forward(\n",
    "        inputs, initial_state, dummy, kernel, training=False)\n",
    "\n",
    "    # Transpose outputs from time-major to batch-major.\n",
    "    hidden = tf.transpose(hidden, [1, 0, 2])\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit TensorFlow implementation of CuDNN GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CuDNN GRU only runs on GPU, so if we want to run inference on a CPU, we can use an explicit TensorFlow implementation based on `tf.while_loop` instead. (An explicit implementation is also useful if we want to experiment with specific changes to the GRU equations that are not supported by the CuDNN cell.)\n",
    "\n",
    "To extract the explicit weights and biases from the CuDNN GRU weight buffer, we can use the `_OpaqueParamsToCanonical()`. This gives us a list of weights and a list of biases, which can be manually processed to build the indivdual weights and biases used in the GRU equations ($W_r$, $W_u$, $W_h$, $R_r$, $R_u$, $R_h$, $b_{Wr}$, $b_{Wu}$, $b_{Wh}$, $b_{Rr}$, $b_{Ru}$, $b_{Rh}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cudnn_gru_explicit(inputs, input_channels, recurrent_size):\n",
    "    \"\"\"\n",
    "    Run a replica of the CuDNN GRU cell manually, using a slow\n",
    "    TensorFlow while-loop and explicit GRU equations.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input tensor, shape [batch_size, timesteps, input_channels].\n",
    "        input_channels: Number of input channels.\n",
    "        recurrent_size: Size of GRU hidden state.\n",
    "        \n",
    "    Returns:\n",
    "        TF node corresponding to GRU outputs.\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    timesteps = tf.shape(inputs)[1]\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope(\"GRU\"):\n",
    "        kernel = tf.get_variable(\"Kernel\",\n",
    "            shape=[recurrent_size *\n",
    "                (3 * recurrent_size + 3 * input_channels + 6)],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    # Extract lists of weights/biases from the CuDNN GRU weight buffer.\n",
    "    saveable = cudnn_rnn_ops.CudnnGRUSaveable(\n",
    "        kernel, 1, recurrent_size, input_channels)\n",
    "    weights, biases = saveable._OpaqueParamsToCanonical()\n",
    "    \n",
    "    # Build the individual weights and biases.\n",
    "    W_r = tf.transpose(weights[0])\n",
    "    W_u = tf.transpose(weights[1])\n",
    "    W_h = tf.transpose(weights[2])\n",
    "    R_r = tf.transpose(weights[3])\n",
    "    R_u = tf.transpose(weights[4])\n",
    "    R_h = tf.transpose(weights[5])\n",
    "    b_Wr = tf.expand_dims(biases[0], 0)\n",
    "    b_Wu = tf.expand_dims(biases[1], 0)\n",
    "    b_Wh = tf.expand_dims(biases[2], 0)\n",
    "    b_Rr = tf.expand_dims(biases[3], 0)\n",
    "    b_Ru = tf.expand_dims(biases[4], 0)\n",
    "    b_Rh = tf.expand_dims(biases[5], 0) \n",
    "\n",
    "    def condition(i, *_state):\n",
    "        \"\"\"Stopping condition.\"\"\"\n",
    "        return tf.less(i, timesteps)\n",
    "\n",
    "    def body(i, state, array):\n",
    "        \"\"\"Loop body.\"\"\"\n",
    "        # Run a single step of explicit GRU using the above weights/biases.\n",
    "        state = run_gru_step(state, inputs[:, i, :], \n",
    "                             W_r, W_u, W_h, \n",
    "                             R_r, R_u, R_h,\n",
    "                             b_Wr, b_Wu, b_Wh,\n",
    "                             b_Rr, b_Ru, b_Rh)\n",
    "        array = array.write(i, state)\n",
    "        return i + 1, state, array\n",
    "\n",
    "    initial_state = [\n",
    "        tf.constant(0),\n",
    "        tf.zeros((batch_size, recurrent_size), dtype=tf.float32),\n",
    "        tf.TensorArray(tf.float32, size=timesteps),\n",
    "    ]\n",
    "    final_state = tf.while_loop(condition, body, initial_state)\n",
    "    return tf.transpose(final_state[-1].stack(), [1, 0, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single forward step is easy to implement using the GRU equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GRU equations](img/gru_small.png \"GRU equations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gru_step(state, inp, W_r, W_u, W_h, R_r, R_u, R_h,\n",
    "                 b_Wr, b_Wu, b_Wh, b_Rr, b_Ru, b_Rh):\n",
    "    \"\"\"\n",
    "    A carbon copy of the CuDNN-GRU forward-step.\n",
    "    \n",
    "    Args:\n",
    "        state:            Previous hidden state,\n",
    "                          shape [batch_size, recurrent_size].\n",
    "        inp:              Input tensor, \n",
    "                          shape [batch_size, input_channels].\n",
    "        W_r, W_u, W_h:    Weights applied to input,\n",
    "                          each with shape [input_channels, recurrent_size].\n",
    "        R_r, R_u, R_h:    Weights applied to previous hidden state,\n",
    "                          each with shape [recurrent_size, recurrent_size].\n",
    "        b_Wr, b_Wu, b_Wh: Biases applied to input transform,\n",
    "                          each with shape [1, recurrent_size].\n",
    "        b_Rr, b_Ru, b_Rh: Biases applied to hidden state transform,\n",
    "                          each with shape [1, recurrent_size].\n",
    "    Returns:\n",
    "        New hidden state, shape [batch_size, recurrent_size]\n",
    "    \"\"\"\n",
    "    # Individual matrix multiplies are shown for clarity; these would be \n",
    "    # more computationally efficient in block form.\n",
    "    X_r = tf.matmul(inp, W_r) + b_Wr\n",
    "    X_u = tf.matmul(inp, W_u) + b_Wu\n",
    "    X_h = tf.matmul(inp, W_h) + b_Wh\n",
    "    H_r = tf.matmul(state, R_r) + b_Rr\n",
    "    H_u = tf.matmul(state, R_u) + b_Ru\n",
    "    H_h = tf.matmul(state, R_h) + b_Rh\n",
    "    \n",
    "    r = tf.nn.sigmoid(X_r + H_r)\n",
    "    u = tf.nn.sigmoid(X_u + H_u)\n",
    "    candidate = tf.tanh(X_h + r * H_h)\n",
    "    state = state * u + candidate * (1 - u)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: compare both models w/ same input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a forward pass using a random input array to confirm that both implementations give the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs of forward pass using CuDNN GRU cell:\n",
      "\n",
      "(1, 10, 256)\n",
      "[[[ 1.0947134e-02  5.3554983e-04 -3.4574396e-03 ... -3.3140765e-05\n",
      "   -3.8697512e-03  4.5041819e-03]\n",
      "  [ 9.0450915e-03 -3.1024218e-03  4.7755952e-04 ...  1.0971370e-03\n",
      "   -5.9758904e-03  7.8519406e-03]\n",
      "  [ 1.1812703e-02 -7.2304592e-03  3.4528917e-03 ... -3.6396014e-03\n",
      "   -6.8984684e-03  1.1104198e-02]\n",
      "  ...\n",
      "  [ 1.5333121e-02 -8.1954943e-03 -7.7663868e-04 ... -8.4617957e-03\n",
      "   -4.9419687e-03  3.2436673e-03]\n",
      "  [ 1.8759312e-02 -8.8395784e-03  1.1147156e-04 ... -9.3853874e-03\n",
      "   -4.9264096e-03  4.8976815e-03]\n",
      "  [ 1.6782669e-02 -7.2793141e-03 -8.4629748e-03 ... -5.4480475e-03\n",
      "   -2.0670865e-03  6.7125186e-03]]]\n",
      "\n",
      "\n",
      "Outputs of forward pass using explicit TensorFlow operations and `tf.while_loop`:\n",
      "\n",
      "(1, 10, 256)\n",
      "[[[ 1.0947133e-02  5.3554960e-04 -3.4574401e-03 ... -3.3140306e-05\n",
      "   -3.8697512e-03  4.5041828e-03]\n",
      "  [ 9.0450915e-03 -3.1024241e-03  4.7755882e-04 ...  1.0971368e-03\n",
      "   -5.9758904e-03  7.8519396e-03]\n",
      "  [ 1.1812702e-02 -7.2304606e-03  3.4528908e-03 ... -3.6396021e-03\n",
      "   -6.8984688e-03  1.1104197e-02]\n",
      "  ...\n",
      "  [ 1.5333120e-02 -8.1954943e-03 -7.7663816e-04 ... -8.4617976e-03\n",
      "   -4.9419682e-03  3.2436671e-03]\n",
      "  [ 1.8759312e-02 -8.8395774e-03  1.1147230e-04 ... -9.3853893e-03\n",
      "   -4.9264086e-03  4.8976806e-03]\n",
      "  [ 1.6782669e-02 -7.2793127e-03 -8.4629748e-03 ... -5.4480489e-03\n",
      "   -2.0670856e-03  6.7125177e-03]]]\n"
     ]
    }
   ],
   "source": [
    "RECURRENT_SIZE = 256\n",
    "BATCH_SIZE = 1\n",
    "TIMESTEPS = 10\n",
    "INPUT_CHANNELS = 100\n",
    "input_shape = (BATCH_SIZE, TIMESTEPS, INPUT_CHANNELS)\n",
    "\n",
    "inp = tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "# Outputs from CuDNN GRU.\n",
    "outputs = run_cudnn_gru(inp, INPUT_CHANNELS, RECURRENT_SIZE)\n",
    "\n",
    "# Outputs from explicit-TF GRU.\n",
    "outputs_explicit = run_cudnn_gru_explicit(inp, INPUT_CHANNELS, RECURRENT_SIZE)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "np.random.seed(9999)\n",
    "inputs = np.random.random_sample(input_shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs = sess.run(outputs, feed_dict={inp: inputs})\n",
    "    print(\"Outputs of forward pass using CuDNN GRU cell:\\n\")\n",
    "    print(\"Shape: {}\".format(outputs.shape))\n",
    "    print(outputs)\n",
    "    print(\"\\n\")\n",
    "    outputs_explicit = sess.run(outputs_explicit, feed_dict={inp: inputs})\n",
    "    print(\"Outputs of forward pass using explicit TensorFlow operations and `tf.while_loop`:\\n\")\n",
    "    print(\"Shape: {}\".format(outputs_explicit.shape))\n",
    "    print(outputs_explicit)"
   ]
  }
 ],
 "metadata": {
  "description": "Fine-tune the ImageNet-trained CaffeNet on new data.",
  "example_name": "Fine-tuning for Style Recognition",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "priority": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
